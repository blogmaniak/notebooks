{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Liquor Sales Predictor\n",
    "#### Predicts the sale by product category given future month and day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib\n",
    "#!pip install bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset file\n",
    "import sys\n",
    "import types\n",
    "import pandas as pd\n",
    "\n",
    "#IBM DSX specific file I/O client libraries\n",
    "#from botocore.client import Config\n",
    "#import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "###########---- ibm dsx specific code to load file ----------###########################\n",
    "## Loads the large 13MM record file\n",
    "## The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "## You might want to remove those credentials before you share your notebook.\n",
    "#client_e0d982f9f7984059b4c6b128d1814552 = ibm_boto3.client(service_name='s3',\n",
    "#ibm_api_key_id='PkAbaFpfA7qkLJYNcF1OasbQWapxuH6P-vycQqiofFvK',\n",
    "#ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n",
    "#config=Config(signature_version='oauth'),\n",
    "#endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n",
    "\n",
    "#body = client_e0d982f9f7984059b4c6b128d1814552.get_object(Bucket='cnn-donotdelete-pr-4iz30eoowmkw91',Key='Iowa_Liquor_Sales.csv')['Body']\n",
    "## add missing __iter__ method, so pandas accepts body as file-like object\n",
    "#if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "##insert credentials for file - Change to credentials_1\n",
    "## @hidden_cell\n",
    "## The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "## You might want to remove those credentials before you share your notebook.\n",
    "#credentials_1 = {\n",
    "#    'IBM_API_KEY_ID': 'PkAbaFpfA7qkLJYNcF1OasbQWapxuH6P-vycQqiofFvK',\n",
    "#    'IAM_SERVICE_ID': 'iam-ServiceId-a42a0a9d-b15f-482d-8ad4-7f333af35771',\n",
    "#    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "#    'IBM_AUTH_ENDPOINT': 'https://iam.ng.bluemix.net/oidc/token',\n",
    "#    'BUCKET': 'cnn-donotdelete-pr-4iz30eoowmkw91',\n",
    "#    'FILE': 'liqSales.csv'\n",
    "#}\n",
    "## @hidden_cell\n",
    "## The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "## You might want to remove those credentials before you share your notebook.\n",
    "## Make sure this uses the variable above. The number will vary in the inserted code.\n",
    "#try:\n",
    "#    credentials = credentials_1\n",
    "#except NameError as e:\n",
    "#    print('Error: Setup is incorrect or incomplete.\\n')\n",
    "#    print('Follow the instructions to insert the file credentials above, and edit to')\n",
    "#    print('make the generated credentials_# variable match the variable used here.')\n",
    "#    raise\n",
    "#\n",
    "## reference using String\n",
    "#cols = ['Date', 'Category Name', 'Item Description', 'Sale (Dollars)', 'Volume Sold (Liters)']\n",
    "#df = pd.read_csv(body, usecols=cols)\n",
    "###########---- ibm dsx specific code ----------###########################\n",
    "\n",
    "##--- local methods to load file w/ 13MM records ---#\n",
    "#fileLoc = \"../data/Iowa_Liquor_Sales.csv\"\n",
    "#dfs = pd.read_csv(fileLoc)\n",
    "##--- local methods to load file ---#\n",
    "    \n",
    " \n",
    "    \n",
    "#df.head()\n",
    "#count rows and slice into smaller chunk\n",
    "#df['Date'].count()\n",
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_short = df.iloc[0:1000000]\n",
    "#df_short.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Fields to simplify\n",
    "#df_short.rename(columns={'Sale (Dollars)': 'sales'}, inplace=True)\n",
    "#df_short.rename(columns={'Volume Sold (Liters)': 'volume'}, inplace=True)\n",
    "#df_short.rename(columns={'Category Name': 'categoryName'}, inplace=True)\n",
    "#df_short.rename(columns={'Date': 'date'}, inplace=True)\n",
    "#df_short.rename(columns={'Item Description': 'item'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the df Date text to datetime field\n",
    "#import dateutil\n",
    "#df_short['date'] = df_short['date'].apply(dateutil.parser.parse, dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The largest sale possible\n",
    "#df_short['sales'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The largest sale possible\n",
    "#df_short['volume'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print df_short detailss\n",
    "#df_short.index\n",
    "#df_short['date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save to csv file at object storage\n",
    "#cos = ibm_boto3.client(service_name='s3',\n",
    "#    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n",
    "#    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n",
    "#    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n",
    "#    config=Config(signature_version='oauth'),\n",
    "#    endpoint_url=credentials['ENDPOINT'])\n",
    "#\n",
    "## Build the enriched file name from the original filename.\n",
    "#localfilename = 'enriched_' + credentials['FILE']\n",
    "\n",
    "# Write a CSV file from the enriched pandas DataFrame.\n",
    "#df_short.to_csv(localfilename, index=False)\n",
    "\n",
    "# Use the above put_file method with credentials to put the file in Object Storage.\n",
    "#cos.upload_file(localfilename, Bucket=credentials['BUCKET'],Key=localfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -alt \"../work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the shortened file into panda dataframe\n",
    "fileLoc = \"../data/enriched_liqSales.csv\"\n",
    "dfs = pd.read_csv(fileLoc)\n",
    "#dfs.index\n",
    "#list(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Fields to simplify using the df\n",
    "dfs.rename(columns={'Date': 'date'}, inplace=True)\n",
    "dfs.rename(columns={'Store Name': 'storeName'}, inplace=True)\n",
    "dfs.rename(columns={'Zip Code': 'zip'}, inplace=True)\n",
    "dfs.rename(columns={'Store Location': 'storeLocation'}, inplace=True)\n",
    "dfs.rename(columns={'Category Name': 'categoryName'}, inplace=True)\n",
    "dfs.rename(columns={'Vendor Name': 'vendorName'}, inplace=True)\n",
    "dfs.rename(columns={'Item Description': 'item'}, inplace=True)\n",
    "dfs.rename(columns={'Bottle Volume (ml)': 'bottleVol'}, inplace=True)\n",
    "dfs.rename(columns={'State Bottle Cost': 'bottleCost'}, inplace=True)\n",
    "dfs.rename(columns={'State Bottle Retail': 'bottleSalePrice'}, inplace=True)\n",
    "dfs.rename(columns={'Sale (Dollars)': 'txAmount'}, inplace=True)\n",
    "dfs.rename(columns={'Bottles Sold': 'txNumBottleSold'}, inplace=True)\n",
    "dfs.rename(columns={'Volume Sold (Liters)': 'txVolLtrs'}, inplace=True)\n",
    "dfs.rename(columns={'Volume Sold (Gallons)': 'txVolGal'}, inplace=True)\n",
    "#list(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs['txAmount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currently Sales is a text, convert it to float\n",
    "#Also convert all other numerics to float for supporting future transactions\n",
    "dfs['txAmount'] = dfs['txAmount'].str.replace('$', '')\n",
    "dfs['txAmount'] = dfs['txAmount'].astype(float)\n",
    "dfs['Pack'] = dfs['Pack'].astype(float)\n",
    "dfs['bottleVol'] = dfs['bottleVol'].astype(float)\n",
    "dfs['bottleCost'] = dfs['bottleCost'].str.replace('$', '')\n",
    "dfs['bottleCost'] = dfs['bottleCost'].astype(float)\n",
    "dfs['bottleSalePrice'] = dfs['bottleSalePrice'].str.replace('$', '')\n",
    "dfs['bottleSalePrice'] = dfs['bottleSalePrice'].astype(float)\n",
    "dfs['txNumBottleSold'] = dfs['txNumBottleSold'].astype(float)\n",
    "dfs['txVolLtrs'] = dfs['txVolLtrs'].astype(float)\n",
    "\n",
    "#df_short.head()\n",
    "\n",
    "#Convert date field to panda date/time\n",
    "dfs['date'] = pd.to_datetime(dfs['date'])\n",
    "\n",
    "#Insert columns to indicate Month\n",
    "dfs['month'] = dfs['date'].dt.month\n",
    "\n",
    "#Insert columns to indicate dayofweek\n",
    "dfs['dayofweek'] = dfs['date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the latitude and longitude from storeLocation\n",
    "#(?<=\\().*?(?=\\)) looks for everything between () in 1013 MAIN\\nKEOKUK 52632\\n(40.39978, -91.387531)\n",
    "#Then it breaks into individual lat/long using , delimiter\n",
    "dfs['latlong'] = dfs['storeLocation'].str.extract('((?<=\\().*?(?=\\)))', expand=True)\n",
    "dfs[['lat','long']]  = dfs['latlong'].str.split(',', expand=True)\n",
    "#dfs['lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the profit per day, based on (txAmount - (bottleCost*txNumBottleSold))\n",
    "dfs['dailyProfit'] = dfs['txAmount'] - (dfs['bottleCost']*dfs['txNumBottleSold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>storeName</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>zip</th>\n",
       "      <th>storeLocation</th>\n",
       "      <th>categoryName</th>\n",
       "      <th>vendorName</th>\n",
       "      <th>item</th>\n",
       "      <th>Pack</th>\n",
       "      <th>...</th>\n",
       "      <th>txNumBottleSold</th>\n",
       "      <th>txAmount</th>\n",
       "      <th>txVolLtrs</th>\n",
       "      <th>txVolGal</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>latlong</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>dailyProfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-20</td>\n",
       "      <td>Keokuk Spirits</td>\n",
       "      <td>1013 MAIN</td>\n",
       "      <td>KEOKUK</td>\n",
       "      <td>52632</td>\n",
       "      <td>1013 MAIN\\nKEOKUK 52632\\n(40.39978, -91.387531)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wilson Daniels Ltd.</td>\n",
       "      <td>Templeton Rye w/Flask</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>162.84</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.19</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>40.39978, -91.387531</td>\n",
       "      <td>40.39978</td>\n",
       "      <td>-91.387531</td>\n",
       "      <td>54.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-21</td>\n",
       "      <td>Ding's Honk And Holler</td>\n",
       "      <td>900 E WASHINGTON</td>\n",
       "      <td>CLARINDA</td>\n",
       "      <td>51632</td>\n",
       "      <td>900 E WASHINGTON\\nCLARINDA 51632\\n(40.739238, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wilson Daniels Ltd.</td>\n",
       "      <td>Templeton Rye w/Flask</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>325.68</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>40.739238, -95.02756</td>\n",
       "      <td>40.739238</td>\n",
       "      <td>-95.02756</td>\n",
       "      <td>108.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-16</td>\n",
       "      <td>Quicker Liquor Store</td>\n",
       "      <td>1414 48TH ST</td>\n",
       "      <td>FORT MADISON</td>\n",
       "      <td>52627</td>\n",
       "      <td>1414 48TH ST\\nFORT MADISON 52627\\n(40.624226, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disaronno International LLC</td>\n",
       "      <td>Disaronno Amaretto Cavalli Mignon 3-50ml Pack</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.08</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>40.624226, -91.373211</td>\n",
       "      <td>40.624226</td>\n",
       "      <td>-91.373211</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>Hy-Vee Food Store #2 / Iowa City</td>\n",
       "      <td>812  S 1ST AVE</td>\n",
       "      <td>IOWA CITY</td>\n",
       "      <td>52240</td>\n",
       "      <td>812 S 1ST AVE\\nIOWA CITY 52240\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jim Beam Brands</td>\n",
       "      <td>Knob Creek w/ Crystal Decanter</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>160.02</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.39</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-17</td>\n",
       "      <td>Twin Town Liquor</td>\n",
       "      <td>104 HIGHWAY 30 WEST</td>\n",
       "      <td>TOLEDO</td>\n",
       "      <td>52342</td>\n",
       "      <td>104 HIGHWAY 30 WEST\\nTOLEDO 52342\\n(41.985887,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disaronno International LLC</td>\n",
       "      <td>Disaronno Amaretto Cavalli Mignon 3-50ml Pack</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.08</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>41.985887, -92.579244</td>\n",
       "      <td>41.985887</td>\n",
       "      <td>-92.579244</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                         storeName              Address  \\\n",
       "0 2015-11-20                    Keokuk Spirits            1013 MAIN   \n",
       "1 2015-11-21            Ding's Honk And Holler     900 E WASHINGTON   \n",
       "2 2015-11-16              Quicker Liquor Store         1414 48TH ST   \n",
       "3 2015-11-04  Hy-Vee Food Store #2 / Iowa City       812  S 1ST AVE   \n",
       "4 2015-11-17                  Twin Town Liquor  104 HIGHWAY 30 WEST   \n",
       "\n",
       "           City    zip                                      storeLocation  \\\n",
       "0        KEOKUK  52632    1013 MAIN\\nKEOKUK 52632\\n(40.39978, -91.387531)   \n",
       "1      CLARINDA  51632  900 E WASHINGTON\\nCLARINDA 51632\\n(40.739238, ...   \n",
       "2  FORT MADISON  52627  1414 48TH ST\\nFORT MADISON 52627\\n(40.624226, ...   \n",
       "3     IOWA CITY  52240                   812 S 1ST AVE\\nIOWA CITY 52240\\n   \n",
       "4        TOLEDO  52342  104 HIGHWAY 30 WEST\\nTOLEDO 52342\\n(41.985887,...   \n",
       "\n",
       "  categoryName                   vendorName  \\\n",
       "0          NaN          Wilson Daniels Ltd.   \n",
       "1          NaN          Wilson Daniels Ltd.   \n",
       "2          NaN  Disaronno International LLC   \n",
       "3          NaN              Jim Beam Brands   \n",
       "4          NaN  Disaronno International LLC   \n",
       "\n",
       "                                            item  Pack     ...      \\\n",
       "0                          Templeton Rye w/Flask   6.0     ...       \n",
       "1                          Templeton Rye w/Flask   6.0     ...       \n",
       "2  Disaronno Amaretto Cavalli Mignon 3-50ml Pack  20.0     ...       \n",
       "3                 Knob Creek w/ Crystal Decanter   3.0     ...       \n",
       "4  Disaronno Amaretto Cavalli Mignon 3-50ml Pack  20.0     ...       \n",
       "\n",
       "   txNumBottleSold  txAmount  txVolLtrs  txVolGal  month  dayofweek  \\\n",
       "0              6.0    162.84       4.50      1.19     11          4   \n",
       "1             12.0    325.68       9.00      2.38     11          5   \n",
       "2              2.0     19.20       0.30      0.08     11          0   \n",
       "3              3.0    160.02       5.25      1.39     11          2   \n",
       "4              2.0     19.20       0.30      0.08     11          1   \n",
       "\n",
       "                 latlong        lat         long dailyProfit  \n",
       "0   40.39978, -91.387531   40.39978   -91.387531       54.30  \n",
       "1   40.739238, -95.02756  40.739238    -95.02756      108.60  \n",
       "2  40.624226, -91.373211  40.624226   -91.373211        6.40  \n",
       "3                    NaN        NaN          NaN       53.37  \n",
       "4  41.985887, -92.579244  41.985887   -92.579244        6.40  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfs['txAmount']\n",
    "#dfs.head()\n",
    "#list(dfs)\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>storeName</th>\n",
       "      <th>item</th>\n",
       "      <th>txAmount</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>latlong</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>dailyProfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-20</td>\n",
       "      <td>Keokuk Spirits</td>\n",
       "      <td>Templeton Rye w/Flask</td>\n",
       "      <td>162.84</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>40.39978, -91.387531</td>\n",
       "      <td>40.39978</td>\n",
       "      <td>-91.387531</td>\n",
       "      <td>54.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-21</td>\n",
       "      <td>Ding's Honk And Holler</td>\n",
       "      <td>Templeton Rye w/Flask</td>\n",
       "      <td>325.68</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>40.739238, -95.02756</td>\n",
       "      <td>40.739238</td>\n",
       "      <td>-95.02756</td>\n",
       "      <td>108.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-16</td>\n",
       "      <td>Quicker Liquor Store</td>\n",
       "      <td>Disaronno Amaretto Cavalli Mignon 3-50ml Pack</td>\n",
       "      <td>19.20</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>40.624226, -91.373211</td>\n",
       "      <td>40.624226</td>\n",
       "      <td>-91.373211</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>Hy-Vee Food Store #2 / Iowa City</td>\n",
       "      <td>Knob Creek w/ Crystal Decanter</td>\n",
       "      <td>160.02</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-17</td>\n",
       "      <td>Twin Town Liquor</td>\n",
       "      <td>Disaronno Amaretto Cavalli Mignon 3-50ml Pack</td>\n",
       "      <td>19.20</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>41.985887, -92.579244</td>\n",
       "      <td>41.985887</td>\n",
       "      <td>-92.579244</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                         storeName  \\\n",
       "0 2015-11-20                    Keokuk Spirits   \n",
       "1 2015-11-21            Ding's Honk And Holler   \n",
       "2 2015-11-16              Quicker Liquor Store   \n",
       "3 2015-11-04  Hy-Vee Food Store #2 / Iowa City   \n",
       "4 2015-11-17                  Twin Town Liquor   \n",
       "\n",
       "                                            item  txAmount  month  dayofweek  \\\n",
       "0                          Templeton Rye w/Flask    162.84     11          4   \n",
       "1                          Templeton Rye w/Flask    325.68     11          5   \n",
       "2  Disaronno Amaretto Cavalli Mignon 3-50ml Pack     19.20     11          0   \n",
       "3                 Knob Creek w/ Crystal Decanter    160.02     11          2   \n",
       "4  Disaronno Amaretto Cavalli Mignon 3-50ml Pack     19.20     11          1   \n",
       "\n",
       "                 latlong        lat         long  dailyProfit  \n",
       "0   40.39978, -91.387531   40.39978   -91.387531        54.30  \n",
       "1   40.739238, -95.02756  40.739238    -95.02756       108.60  \n",
       "2  40.624226, -91.373211  40.624226   -91.373211         6.40  \n",
       "3                    NaN        NaN          NaN        53.37  \n",
       "4  41.985887, -92.579244  41.985887   -92.579244         6.40  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create df for byItem, byLat, byLong all numeric columns\n",
    "dfsModel = dfs[['date','storeName','item','txAmount','month','dayofweek','latlong','lat','long','dailyProfit']]\n",
    "dfsModel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debut to explore data, where a given store has multiple locations but lat/long\n",
    "#import numpy as np\n",
    "#list(dfsModel)\n",
    "#dfsUnq = dfsModel.groupby(\"storeName\").agg({\"txAmount\": np.sum, \"latlong\": pd.Series.nunique})\n",
    "#dfsUnq = dfsUnq.sort_values('storeName')\n",
    "#dfsUnq.head(1000)\n",
    "\n",
    "#show dfs by storeName\n",
    "#dfs.loc[dfs['storeName'] == 'Liquor and Tobacco Outlet /']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To-Do --- visualize early dfs\n",
    "#Show profit graph over date/time\n",
    "#from bokeh.io import output_notebook, show\n",
    "#from bokeh.plotting import figure\n",
    "#output_notebook()\n",
    "\n",
    "#profitShow = TimeSeries(dfs, x=date, y=[dailyProfit], legend=True, plot_width=900, plot_height=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Generate sales histogram by distribution\n",
    "#import numpy as np\n",
    "#from numpy import argmax\n",
    "#from bokeh.plotting import figure\n",
    "#from bokeh.io import show, output_notebook\n",
    "#\n",
    "## Create a blank figure with labels\n",
    "#p = figure(plot_width = 600, plot_height = 600, \n",
    "#           title = 'Sales Amount Distribution',\n",
    "#           x_axis_label = 'X', y_axis_label = 'Y')\n",
    "#\n",
    "##Build the histogram with bin range between $0-$150\n",
    "##Bin size of 15 dollars\n",
    "#arr_hist, edges = np.histogram(dfs['txAmount'], \n",
    "#                               bins = int(1200/50), \n",
    "#                               range = [0, 1200])\n",
    "## Put the information in a dataframe\n",
    "#dfSale = pd.DataFrame({'NumTxs': arr_hist, \n",
    "#                       'left': edges[:-1], \n",
    "#                       'right': edges[1:]})\n",
    "#dfSale\n",
    "##arr_hist, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the blank plot\n",
    "#p = figure(plot_height = 600, plot_width = 600, \n",
    "#           title = 'Distribution of Sales',\n",
    "#          x_axis_label = 'Transaction Amount', \n",
    "#           y_axis_label = 'Number Of Transactions') \n",
    "#\n",
    "## Add a quad glyph\n",
    "#p.quad(bottom=0, top=dfSale['NumTxs'], \n",
    "#       left=dfSale['left'], right=dfSale['right'], \n",
    "#       fill_color='#E83151', line_color='#DBD4D3')\n",
    "#\n",
    "## Show the plot\n",
    "#show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##testing encoder\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#encoder = LabelEncoder()\n",
    "#dfs['categoryNameCode'] = encoder.fit_transform(dfs['categoryName'])\n",
    "##encoder.fit_transform(dfs.loc[:, ['categoryName', 'item']])\n",
    "#dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform df to aggregate sales, volume by item for given date\n",
    "#dfTItem = dfs.drop('categoryName', axis=1)\n",
    "#dfTItem = dfTItem.groupby([\"date\", 'item'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-c622cbdeab45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#Generate OneHotEncoded for all category sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mdfOHE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfsModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'storeName'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'itm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;31m#Concat the main dfTItem with OHE df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mdfsModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfsModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfOHE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhan/src/anaconda/anaconda2/envs/kerasJupyter/lib/python2.7/site-packages/pandas/core/reshape/reshape.pyc\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    880\u001b[0m                                     drop_first=drop_first, dtype=dtype)\n\u001b[1;32m    881\u001b[0m             \u001b[0mwith_dummies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         result = _get_dummies_1d(data, prefix, prefix_sep, dummy_na,\n",
      "\u001b[0;32m/home/bhan/src/anaconda/anaconda2/envs/kerasJupyter/lib/python2.7/site-packages/pandas/core/reshape/concat.pyc\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                        copy=copy, sort=sort)\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhan/src/anaconda/anaconda2/envs/kerasJupyter/lib/python2.7/site-packages/pandas/core/reshape/concat.pyc\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m    422\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                 copy=self.copy)\n\u001b[0m\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhan/src/anaconda/anaconda2/envs/kerasJupyter/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   5410\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5411\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5412\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5413\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5414\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#generate the final encoded, transformed, shifted and inferred ready df\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "#lets build dfTransform, class that allows to fit and transform\n",
    "#selected label columns\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "    \n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = encoder.fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = encoder.fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)\n",
    "\n",
    "#Fit and Transform the label columns\n",
    "#dfTItem = MultiColumnLabelEncoder(columns = ['item']).fit_transform(dfTItem)\n",
    "\n",
    "#Generate OneHotEncoded for all category sets\n",
    "dfOHE = pd.get_dummies(dfsModel[['storeName','item']], prefix=['sN', 'itm'])\n",
    "#Concat the main dfTItem with OHE df\n",
    "dfsModel = pd.concat([dfsModel, dfOHE], axis=1)\n",
    "#dfTransform[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>storeName</th>\n",
       "      <th>item</th>\n",
       "      <th>txAmount</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>latlong</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>dailyProfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-20</td>\n",
       "      <td>Keokuk Spirits</td>\n",
       "      <td>Templeton Rye w/Flask</td>\n",
       "      <td>162.84</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>40.39978, -91.387531</td>\n",
       "      <td>40.39978</td>\n",
       "      <td>-91.387531</td>\n",
       "      <td>54.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-21</td>\n",
       "      <td>Ding's Honk And Holler</td>\n",
       "      <td>Templeton Rye w/Flask</td>\n",
       "      <td>325.68</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>40.739238, -95.02756</td>\n",
       "      <td>40.739238</td>\n",
       "      <td>-95.02756</td>\n",
       "      <td>108.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-16</td>\n",
       "      <td>Quicker Liquor Store</td>\n",
       "      <td>Disaronno Amaretto Cavalli Mignon 3-50ml Pack</td>\n",
       "      <td>19.20</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>40.624226, -91.373211</td>\n",
       "      <td>40.624226</td>\n",
       "      <td>-91.373211</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>Hy-Vee Food Store #2 / Iowa City</td>\n",
       "      <td>Knob Creek w/ Crystal Decanter</td>\n",
       "      <td>160.02</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-17</td>\n",
       "      <td>Twin Town Liquor</td>\n",
       "      <td>Disaronno Amaretto Cavalli Mignon 3-50ml Pack</td>\n",
       "      <td>19.20</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>41.985887, -92.579244</td>\n",
       "      <td>41.985887</td>\n",
       "      <td>-92.579244</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                         storeName  \\\n",
       "0 2015-11-20                    Keokuk Spirits   \n",
       "1 2015-11-21            Ding's Honk And Holler   \n",
       "2 2015-11-16              Quicker Liquor Store   \n",
       "3 2015-11-04  Hy-Vee Food Store #2 / Iowa City   \n",
       "4 2015-11-17                  Twin Town Liquor   \n",
       "\n",
       "                                            item  txAmount  month  dayofweek  \\\n",
       "0                          Templeton Rye w/Flask    162.84     11          4   \n",
       "1                          Templeton Rye w/Flask    325.68     11          5   \n",
       "2  Disaronno Amaretto Cavalli Mignon 3-50ml Pack     19.20     11          0   \n",
       "3                 Knob Creek w/ Crystal Decanter    160.02     11          2   \n",
       "4  Disaronno Amaretto Cavalli Mignon 3-50ml Pack     19.20     11          1   \n",
       "\n",
       "                 latlong        lat         long  dailyProfit  \n",
       "0   40.39978, -91.387531   40.39978   -91.387531        54.30  \n",
       "1   40.739238, -95.02756  40.739238    -95.02756       108.60  \n",
       "2  40.624226, -91.373211  40.624226   -91.373211         6.40  \n",
       "3                    NaN        NaN          NaN        53.37  \n",
       "4  41.985887, -92.579244  41.985887   -92.579244         6.40  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsModel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert first example\n",
    "#dfOHE\n",
    "argmax(dfOHE.iloc[3, :])\n",
    "#inverted = encoder.inverse_transform([argmax(dfOHE.iloc[0, :])])\n",
    "#print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all unique classes across both labels\n",
    "#list(encoder.classes_)\n",
    "#len(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering and \n",
    "from pandas import concat\n",
    "#Append the shifted metrics for adding predictability trends over time steps i.e. 1 day\n",
    "#Original headers:date\tcategoryName\titem\tsales\tvolume\n",
    "width = 3\n",
    "\n",
    "#Shift the sales column by set width\n",
    "shifted = dfTransform.loc[:, ['sales']].shift(width - 1)\n",
    "window = shifted.rolling(window=width)\n",
    "dfTransform = concat([dfTransform, window.min(), window.mean(), window.max()], axis=1)\n",
    "dfTransform.columns = ['date', 'categoryName', 'item', 'sales', 'volume', 'salesMin', 'salesMean', 'salesMax']\n",
    "\n",
    "#Shift the volume column by set width\n",
    "shifted = dfTransform.loc[:, ['volume']].shift(width - 1)\n",
    "window = shifted.rolling(window=width)\n",
    "dfTransform = concat([dfTransform, window.min(), window.mean(), window.max()], axis=1)\n",
    "dfTransform.columns = ['date', 'categoryName', 'item', 'sales', 'volume', 'salesMin', 'salesMean', 'salesMax', 'volMin', 'volMean', 'volMax']\n",
    "\n",
    "dfTransform[:10]\n",
    "#shifted[:10]\n",
    "#window\n",
    "#dfTransform.columns = ['min', 'mean', 'max', 't+1', 'date', 'categoryName', 'item', 'sales', 'volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add shifted Exponentially Weighted Windows to dataframe\n",
    "#dfTransform.loc[:, ['salesMean']]\n",
    "#ema = dfTransform.loc[:, ['salesMean']].ewm(com=0.5, min_periods=2, axis=1).mean()\n",
    "#ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "values = dfs.values\n",
    "# specify columns to plot\n",
    "groups = [3,4]\n",
    "i = 1\n",
    "# plot each column\n",
    "pyplot.figure()\n",
    "for group in groups:\n",
    "\tpyplot.subplot(len(groups), 1, i)\n",
    "\tpyplot.plot(values[:, group])\n",
    "\tpyplot.title(dfs.columns[group], y=0.5, loc='right')\n",
    "\ti += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the LSTM model\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    " \n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "print(reframed.head())\n",
    " \n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    " \n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    " \n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
